#!/usr/bin/env python3
"""
å¢å¼ºçš„Graphitiæ—¶åºçŸ¥è¯†å›¾è°±æœåŠ¡

åŸºäºgraphiti_coreçš„å°è£…ï¼Œæä¾›ï¼š
1. graphiti_coreçš„å®Œæ•´åŒæ—¶åºåŠŸèƒ½
2. æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜æœºåˆ¶
3. ç»Ÿä¸€çš„APIæ¥å£
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Union
import json
import uuid
from datetime import datetime, timezone
import time
import hashlib
from functools import lru_cache
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# å¯¼å…¥é…ç½®
try:
    from api_service.config.settings import settings
except ImportError:
    try:
        config_path = os.path.join(project_root, 'config', 'settings.py')
        import importlib.util
        spec = importlib.util.spec_from_file_location("settings", config_path)
        settings_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(settings_module)
        settings = settings_module.settings
    except Exception as e:
        print(f"å¯¼å…¥é…ç½®å¤±è´¥: {e}")
        class DefaultSettings:
            TEMPORAL_QUERY_CACHE_TTL = 300
            TEMPORAL_QUERY_CACHE_SIZE = 10000
        settings = DefaultSettings()

logger = logging.getLogger(__name__)


class EnhancedGraphitiService:
    """å¢å¼ºçš„GraphitiæœåŠ¡ï¼ŒåŸºäºgraphiti_core"""
    
    def __init__(self, driver=None):
        """åˆå§‹åŒ–å¢å¼ºGraphitiæœåŠ¡"""
        # graphiti_coreå®ä¾‹
        self._graphiti_core = None
        self._graphiti_core_enabled = False
        
        # å°è¯•åˆå§‹åŒ–graphiti_core
        try:
            self._init_graphiti_core()
            logger.info("âœ… graphiti_coreåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸  graphiti_coreåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            logger.info("ğŸ’¡ æç¤º: è¯·ç¡®ä¿Neo4jæ­£åœ¨è¿è¡Œï¼Œä¸”ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®")
        
        # æ€§èƒ½ä¼˜åŒ–ç¼“å­˜
        self._query_cache = {}
        self._cache_hits = 0
        self._cache_misses = 0
        
        logger.info("âœ… å¢å¼ºGraphitiæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def _init_graphiti_core(self):
        """åˆå§‹åŒ–graphiti_core"""
        try:
            from graphiti_core import Graphiti
            from graphiti_core.llm_client import LLMClient
            
            # ä»ç¯å¢ƒå˜é‡è·å–Neo4jè¿æ¥ä¿¡æ¯
            neo4j_uri = os.environ.get('NEO4J_URI', 'bolt://localhost:7687')
            neo4j_user = os.environ.get('NEO4J_USER', 'neo4j')
            neo4j_password = os.environ.get('NEO4J_PASSWORD', 'password')
            
            # è·å–OpenAI APIé…ç½®
            openai_api_key = os.environ.get('OPENAI_API_KEY', '')
            openai_base_url = os.environ.get('OPENAI_BASE_URL', None)
            openai_model = os.environ.get('OPENAI_MODEL', 'gpt-4o-mini')
            
            logger.info(f"ğŸ”— è¿æ¥Neo4j: {neo4j_uri}")
            if openai_base_url:
                logger.info(f"ğŸ¤– ä½¿ç”¨è‡ªå®šä¹‰APIç«¯ç‚¹: {openai_base_url}")
                logger.info(f"ğŸ“¦ ä½¿ç”¨LLMæ¨¡å‹: {openai_model}")
            
            # åˆå§‹åŒ–graphiti_coreï¼Œä¼ é€’OpenAI APIå¯†é’¥
            if openai_api_key:
                # å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆgraphiti_coreä¼šè¯»å–ï¼‰
                os.environ['OPENAI_API_KEY'] = openai_api_key
                if openai_base_url:
                    os.environ['OPENAI_BASE_URL'] = openai_base_url
                os.environ['OPENAI_MODEL'] = openai_model
            
            # åˆ›å»ºGraphitiå®ä¾‹ï¼Œé…ç½®LLM
            self._graphiti_core = Graphiti(neo4j_uri, neo4j_user, neo4j_password)
            self._graphiti_core_enabled = True
            
        except ImportError as e:
            raise ImportError(f"âŒ æ— æ³•å¯¼å…¥graphiti_core: {str(e)}ã€‚è¯·è¿è¡Œ: pip install graphiti-core")
        except Exception as e:
            raise Exception(f"âŒ åˆå§‹åŒ–graphiti_coreå¤±è´¥: {str(e)}")
    
    # ========== graphiti_core Episodeç®¡ç† ==========
    
    def add_episode_graphiti_core(self, content: Union[str, Dict[str, Any]],
                                  episode_type: str = "text",
                                  name: Optional[str] = None,
                                  source: Optional[str] = None,
                                  source_description: Optional[str] = None,
                                  reference_time: Optional[Union[str, datetime]] = None,
                                  metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨graphiti_coreæ·»åŠ Episode
        
        Args:
            content: Episodeå†…å®¹ï¼ˆæ–‡æœ¬æˆ–JSONï¼‰
            episode_type: Episodeç±»å‹ï¼ˆtext/json/messageï¼‰
            name: Episodeåç§°ï¼ˆå¯é€‰ï¼‰
            source: æ¥æºæ ‡è¯†
            source_description: æ¥æºæè¿°
            reference_time: å‚è€ƒæ—¶é—´
            metadata: å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ·»åŠ ç»“æœ
        """
        if not self._graphiti_core_enabled:
            return {
                "success": False,
                "error": "graphiti_coreæœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥"
            }
        
        try:
            from graphiti_core.nodes import EpisodeType
            
            # è½¬æ¢ç±»å‹
            if episode_type == "text":
                episode_type_enum = EpisodeType.text
                episode_body = content
            elif episode_type == "json":
                episode_type_enum = EpisodeType.json
                if isinstance(content, dict):
                    episode_body = json.dumps(content)
                else:
                    episode_body = str(content)
            elif episode_type == "message":
                episode_type_enum = EpisodeType.message
                episode_body = json.dumps(content) if isinstance(content, dict) else str(content)
            else:
                episode_type_enum = EpisodeType.text
                episode_body = str(content)
            
            # å¤„ç†æ—¶é—´
            if reference_time:
                if isinstance(reference_time, str):
                    ref_time = datetime.fromisoformat(reference_time.replace('Z', '+00:00'))
                else:
                    ref_time = reference_time
            else:
                ref_time = datetime.now(timezone.utc)
            
            # ç”ŸæˆEpisodeåç§°
            episode_name = name or f"episode_{uuid.uuid4().hex[:8]}"
            
            # å¼‚æ­¥æ‰§è¡Œæ·»åŠ Episode
            async def _add_episode():
                # æ„å»ºå‚æ•°å­—å…¸
                episode_params = {
                    "name": episode_name,
                    "episode_body": episode_body,
                    "source": episode_type_enum,
                    "source_description": source_description or "User input via EnhancedGraphitiService",
                    "reference_time": ref_time
                }
                
                # åªæœ‰å½“metadataä¸ä¸ºNoneæ—¶æ‰æ·»åŠ 
                if metadata is not None:
                    episode_params["metadata"] = metadata
                
                return await self._graphiti_core.add_episode(**episode_params)
            
            result = asyncio.run(_add_episode())
            
            if result:
                return {
                    "success": True,
                    "episode_uuid": str(result.uuid) if hasattr(result, 'uuid') else None,
                    "name": episode_name,
                    "message": "Episodeæ·»åŠ æˆåŠŸ"
                }
            else:
                return {
                    "success": False,
                    "error": "Episodeæ·»åŠ å¤±è´¥ï¼Œè¿”å›ç»“æœä¸ºç©º"
                }
                
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ Episodeå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    # ========== graphiti_core æœç´¢åŠŸèƒ½ ==========
    
    def search_episodes_graphiti_core(self, query: str,
                                       limit: int = 10,
                                       center_node_uuid: Optional[str] = None,
                                       valid_at: Optional[Union[str, datetime]] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨graphiti_coreæœç´¢Episodes
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            limit: è¿”å›ç»“æœé™åˆ¶
            center_node_uuid: å¯é€‰çš„ä¸­å¿ƒèŠ‚ç‚¹UUIDï¼ˆç”¨äºåŸºäºå›¾çš„é‡æ–°æ’åºï¼‰
            valid_at: å¯é€‰çš„æœ‰æ•ˆæ—¶é—´ç‚¹ï¼ˆæ—¶é—´æ—…è¡ŒæŸ¥è¯¢ï¼‰
            
        Returns:
            æœç´¢ç»“æœ
        """
        if not self._graphiti_core_enabled:
            return {
                "success": False,
                "error": "graphiti_coreæœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥"
            }
        
        try:
            # å¼‚æ­¥æ‰§è¡Œæœç´¢
            async def _search():
                if center_node_uuid:
                    results = await self._graphiti_core.search(
                        query=query,
                        center_node_uuid=center_node_uuid
                    )
                else:
                    results = await self._graphiti_core.search(query=query)
                return results
            
            results = asyncio.run(_search())
            
            # è½¬æ¢ç»“æœæ ¼å¼
            formatted_results = []
            for result in results[:limit]:
                formatted_result = {
                    "uuid": str(result.uuid) if hasattr(result, 'uuid') else None,
                    "fact": result.fact if hasattr(result, 'fact') else None,
                }
                
                # å¯é€‰å­—æ®µ
                if hasattr(result, 'source_node_uuid') and result.source_node_uuid:
                    formatted_result["source_node_uuid"] = str(result.source_node_uuid)
                if hasattr(result, 'valid_at') and result.valid_at:
                    formatted_result["valid_at"] = result.valid_at.isoformat()
                if hasattr(result, 'invalid_at') and result.invalid_at:
                    formatted_result["invalid_at"] = result.invalid_at.isoformat()
                if hasattr(result, 'score'):
                    formatted_result["score"] = float(result.score) if hasattr(result.score, '__float__') else result.score
                
                formatted_results.append(formatted_result)
            
            return {
                "success": True,
                "query": query,
                "results": formatted_results,
                "total": len(formatted_results)
            }
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢Episodeså¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def search_nodes_graphiti_core(self, query: str,
                                   limit: int = 5,
                                   use_hybrid_search: bool = True) -> Dict[str, Any]:
        """
        ä½¿ç”¨graphiti_coreæœç´¢èŠ‚ç‚¹ï¼ˆä½¿ç”¨æ··åˆæœç´¢ï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            limit: è¿”å›ç»“æœé™åˆ¶
            use_hybrid_search: æ˜¯å¦ä½¿ç”¨æ··åˆæœç´¢ï¼ˆè¯­ä¹‰+BM25ï¼‰
            
        Returns:
            æœç´¢ç»“æœ
        """
        if not self._graphiti_core_enabled:
            return {
                "success": False,
                "error": "graphiti_coreæœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥"
            }
        
        try:
            from graphiti_core.search.search_config_recipes import NODE_HYBRID_SEARCH_RRF
            
            # ä½¿ç”¨é¢„è®¾çš„æœç´¢é…ç½®
            config = NODE_HYBRID_SEARCH_RRF.model_copy(deep=True)
            config.limit = limit
            
            # å¼‚æ­¥æ‰§è¡Œæœç´¢
            async def _search():
                return await self._graphiti_core._search(
                    query=query,
                    config=config
                )
            
            result = asyncio.run(_search())
            
            # è½¬æ¢èŠ‚ç‚¹ç»“æœ
            formatted_nodes = []
            if hasattr(result, 'nodes'):
                for node in result.nodes:
                    formatted_node = {
                        "uuid": str(node.uuid) if hasattr(node, 'uuid') else None,
                        "name": node.name if hasattr(node, 'name') else None,
                        "summary": node.summary if hasattr(node, 'summary') else None,
                    }
                    
                    # å¯é€‰å­—æ®µ
                    if hasattr(node, 'labels') and node.labels:
                        formatted_node["labels"] = list(node.labels)
                    if hasattr(node, 'created_at') and node.created_at:
                        formatted_node["created_at"] = node.created_at.isoformat()
                    if hasattr(node, 'attributes'):
                        formatted_node["attributes"] = node.attributes if isinstance(node.attributes, dict) else {}
                    
                    formatted_nodes.append(formatted_node)
            
            return {
                "success": True,
                "query": query,
                "nodes": formatted_nodes,
                "total": len(formatted_nodes),
                "search_type": "hybrid" if use_hybrid_search else "basic"
            }
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢èŠ‚ç‚¹å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    # ========== æ—¶é—´æŸ¥è¯¢åŠŸèƒ½ ==========
    
    def get_graph_state_at_time_graphiti_core(self, query_time: Union[str, datetime],
                                              limit: int = 100) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šæ—¶é—´ç‚¹çš„å›¾çŠ¶æ€ï¼ˆæ—¶é—´æ—…è¡ŒæŸ¥è¯¢ï¼‰
        
        Args:
            query_time: æŸ¥è¯¢æ—¶é—´ç‚¹
            limit: è¿”å›ç»“æœé™åˆ¶
            
        Returns:
            å›¾çŠ¶æ€æ•°æ®
        """
        if not self._graphiti_core_enabled:
            return {
                "success": False,
                "error": "graphiti_coreæœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥"
            }
        
        try:
            # å¤„ç†æ—¶é—´
            if isinstance(query_time, str):
                query_dt = datetime.fromisoformat(query_time.replace('Z', '+00:00'))
            else:
                query_dt = query_time
            
            # å¼‚æ­¥æ‰§è¡Œæœç´¢è·å–æ‰€æœ‰ç»“æœ
            async def _get_all():
                # ä½¿ç”¨é€šé…ç¬¦è·å–æ‰€æœ‰ç»“æœ
                results = await self._graphiti_core.search(query="*")
                return results
            
            results = asyncio.run(_get_all())
            
            # è¿‡æ»¤åœ¨æŒ‡å®šæ—¶é—´ç‚¹æœ‰æ•ˆçš„ç»“æœ
            valid_results = []
            for result in results[:limit]:
                is_valid = True
                
                # æ£€æŸ¥valid_at
                if hasattr(result, 'valid_at') and result.valid_at:
                    valid_at_dt = result.valid_at
                    if valid_at_dt > query_dt:
                        is_valid = False
                
                # æ£€æŸ¥invalid_at
                if hasattr(result, 'invalid_at') and result.invalid_at:
                    invalid_at_dt = result.invalid_at
                    if invalid_at_dt <= query_dt:
                        is_valid = False
                
                if is_valid:
                    formatted_result = {
                        "uuid": str(result.uuid) if hasattr(result, 'uuid') else None,
                        "fact": result.fact if hasattr(result, 'fact') else None,
                    }
                    valid_results.append(formatted_result)
            
            return {
                "success": True,
                "query_time": query_dt.isoformat(),
                "total_nodes": len(valid_results),
                "nodes": valid_results
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–å›¾çŠ¶æ€å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    # ========== çŠ¶æ€æŸ¥è¯¢æ–¹æ³• ==========
    
    def is_graphiti_core_enabled(self) -> bool:
        """
        æ£€æŸ¥graphiti_coreæ˜¯å¦å¯ç”¨
        
        Returns:
            Trueå¦‚æœgraphiti_coreå·²å¯ç”¨
        """
        return self._graphiti_core_enabled
    
    def get_graphiti_core_info(self) -> Dict[str, Any]:
        """
        è·å–graphiti_coreçš„é›†æˆä¿¡æ¯
        
        Returns:
            graphiti_coreçŠ¶æ€ä¿¡æ¯
        """
        info = {
            "enabled": self._graphiti_core_enabled,
            "version": "unknown",
            "features": []
        }
        
        if self._graphiti_core_enabled:
            try:
                # å°è¯•è·å–ç‰ˆæœ¬ä¿¡æ¯
                import graphiti_core
                info["version"] = getattr(graphiti_core, "__version__", "0.25.0")
                
                # åˆ—å‡ºå¯ç”¨çš„åŠŸèƒ½
                info["features"] = [
                    "add_episode",
                    "search_episodes",
                    "search_nodes_hybrid",
                    "search_with_center_node",
                    "time_based_query",
                    "bitemporal_model",
                    "hybrid_search"
                ]
                
            except Exception as e:
                info["error"] = str(e)
        
        return info
    
    # ========== æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜ ==========
    
    def _get_cache_key(self, operation: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        param_str = json.dumps(kwargs, sort_keys=True)
        hash_obj = hashlib.md5(f"{operation}:{param_str}".encode())
        return hash_obj.hexdigest()
    
    @lru_cache(maxsize=settings.TEMPORAL_QUERY_CACHE_SIZE)
    def _cached_query(self, query_hash: str, query_func: callable) -> Any:
        """å¸¦ç¼“å­˜çš„æŸ¥è¯¢æ‰§è¡Œ"""
        return query_func()
    
    def query_with_cache(self, operation: str, query_func: callable,
                        cache_ttl: Optional[int] = None, **kwargs) -> Any:
        """æ‰§è¡Œå¸¦ç¼“å­˜çš„æŸ¥è¯¢"""
        cache_ttl = cache_ttl or settings.TEMPORAL_QUERY_CACHE_TTL
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._get_cache_key(operation, **kwargs)
        
        # æ£€æŸ¥ç¼“å­˜
        current_time = time.time()
        if cache_key in self._query_cache:
            cached_data, expiry_time = self._query_cache[cache_key]
            if current_time < expiry_time:
                self._cache_hits += 1
                logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: {operation}")
                return cached_data
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡ŒæŸ¥è¯¢
        self._cache_misses += 1
        logger.debug(f"âŒ ç¼“å­˜æœªå‘½ä¸­: {operation}")
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = query_func()
        
        # ç¼“å­˜ç»“æœ
        expiry_time = current_time + cache_ttl
        self._query_cache[cache_key] = (result, expiry_time)
        
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        if len(self._query_cache) > settings.TEMPORAL_QUERY_CACHE_SIZE * 2:
            self._clean_expired_cache()
        
        return result
    
    def _clean_expired_cache(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ¡ç›®"""
        current_time = time.time()
        expired_keys = [
            key for key, (_, expiry_time) in self._query_cache.items()
            if expiry_time < current_time
        ]
        
        for key in expired_keys:
            del self._query_cache[key]
        
        if expired_keys:
            logger.debug(f"ğŸ§¹ æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜æ¡ç›®")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "cache_size": len(self._query_cache),
            "cache_hits": self._cache_hits,
            "cache_misses": self._cache_misses,
            "hit_rate": self._cache_hits / (self._cache_hits + self._cache_misses)
                if self._cache_hits + self._cache_misses > 0 else 0,
            "total_queries": self._cache_hits + self._cache_misses
        }
    
    # ========== è¾…åŠ©æ–¹æ³• ==========
    
    def clear_cache(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        self._query_cache.clear()
        self._cached_query.cache_clear()
        self._cache_hits = 0
        self._cache_misses = 0
        logger.info("ğŸ§¹ ç¼“å­˜å·²æ¸…é™¤")
    
    def get_service_info(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ä¿¡æ¯"""
        cache_stats = self.get_cache_stats()
        
        return {
            "service_type": "EnhancedGraphitiService",
            "graphiti_core_enabled": self._graphiti_core_enabled,
            "graphiti_core_info": self.get_graphiti_core_info(),
            "cache_stats": cache_stats,
            "timestamp": datetime.now().isoformat()
        }
    
    def close(self):
        """å…³é—­æœåŠ¡"""
        # å…³é—­ç¼“å­˜å’Œèµ„æº
        self.clear_cache()
        
        # å…³é—­graphiti_core
        if self._graphiti_core:
            try:
                asyncio.run(self._graphiti_core.close())
                logger.info("âœ… graphiti_coreå·²å…³é—­")
            except Exception as e:
                logger.warning(f"âš ï¸  å…³é—­graphiti_coreæ—¶å‡ºé”™: {str(e)}")
        
        logger.info("âœ… å¢å¼ºGraphitiæœåŠ¡å·²å®Œå…¨å…³é—­")
