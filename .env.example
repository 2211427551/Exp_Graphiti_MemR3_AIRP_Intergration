# Neo4j配置
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password_here

# Redis配置
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=your_redis_password_here

# API配置
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# LLM配置（可选）- 用于项目LLMService和graphiti_core的LLM服务
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com

# OpenAI兼容API配置（必需）- 用于graphiti_core的Embedding服务
# 推荐：硅基流动（用于Embedding）
# 其他选项：OpenAI官方、阿里云DashScope、智谱AI、月之暗面等
OPENAI_API_KEY=your_openai_api_key_here

# API基础URL（可选）
# 硅基流动=https://api.siliconflow.cn/v1
# 阿里云DashScope=https://dashscope.aliyuncs.com/compatible-mode/v1
# 智谱AI=https://open.bigmodel.cn/api/paas/v4
# 月之暗面=https://api.moonshot.cn/v1
# 留空=使用OpenAI官方API
OPENAI_BASE_URL=https://api.siliconflow.cn/v1

# Embedding模型 - 用于graphiti_core的向量化服务
# 硅基流动推荐: Qwen/Qwen3-Embedding-4B, BAAI/bge-large-zh-v1.5
# OpenAI: text-embedding-3-small, text-embedding-3-large
# 阿里云: text-embedding-v2, text-embedding-v3
# 智谱AI: embedding-2, embedding-3
OPENAI_EMBEDDING_MODEL=Qwen/Qwen3-Embedding-4B

# LLM模型 - 用于graphiti_core的知识提取和推理（使用DeepSeek API）
# DeepSeek: deepseek-chat, deepseek-coder
# 其他提供商的模型（通过配置不同的API密钥和URL）
OPENAI_MODEL=deepseek-chat

# 配置说明：
# - graphiti_core现在支持分离配置LLM和Embedding
# - LLM使用DEEPSEEK_API_KEY和DEEPSEEK_BASE_URL
# - Embedding使用OPENAI_API_KEY和OPENAI_BASE_URL
# - 这种分离配置可以优化成本和性能

# 应用配置
APP_ENV=development
APP_DEBUG=True
LOG_LEVEL=INFO

# Graphiti Core配置
GRAPHITI_CORE_ENABLED=True
